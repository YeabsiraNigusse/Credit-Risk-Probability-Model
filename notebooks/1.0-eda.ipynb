{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Credit Risk Model - Exploratory Data Analysis\n",
    "\n",
    "This notebook performs exploratory data analysis for the credit risk modeling project.\n",
    "We'll analyze customer transaction data and develop RFM-based risk proxies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import warnings\n",
    "from datetime import datetime, timedelta\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Add src to path\n",
    "sys.path.append('../src')\n",
    "\n",
    "from data_processing import RFMAnalyzer, FeatureEngineer\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Loading and Initial Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For demonstration, we'll create synthetic data\n",
    "# In practice, you would load your actual transaction data here\n",
    "\n",
    "def create_synthetic_data(n_customers=1000, seed=42):\n",
    "    \"\"\"\n",
    "    Create synthetic transaction data for demonstration\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    customers = [f\"CUST_{i:04d}\" for i in range(1, n_customers + 1)]\n",
    "    data = []\n",
    "    \n",
    "    base_date = datetime(2023, 1, 1)\n",
    "    end_date = datetime(2024, 12, 31)\n",
    "    \n",
    "    for customer in customers:\n",
    "        # Simulate different customer behaviors\n",
    "        customer_type = np.random.choice(['high_value', 'medium_value', 'low_value', 'churned'], \n",
    "                                       p=[0.15, 0.35, 0.35, 0.15])\n",
    "        \n",
    "        if customer_type == 'high_value':\n",
    "            n_transactions = np.random.randint(50, 200)\n",
    "            amount_range = (100, 1000)\n",
    "            recency_bias = 30  # Recent transactions\n",
    "        elif customer_type == 'medium_value':\n",
    "            n_transactions = np.random.randint(20, 80)\n",
    "            amount_range = (50, 500)\n",
    "            recency_bias = 60\n",
    "        elif customer_type == 'low_value':\n",
    "            n_transactions = np.random.randint(5, 30)\n",
    "            amount_range = (20, 200)\n",
    "            recency_bias = 120\n",
    "        else:  # churned\n",
    "            n_transactions = np.random.randint(1, 10)\n",
    "            amount_range = (10, 100)\n",
    "            recency_bias = 300\n",
    "        \n",
    "        for i in range(n_transactions):\n",
    "            # Bias transaction dates based on customer type\n",
    "            days_back = np.random.exponential(recency_bias)\n",
    "            days_back = min(days_back, 730)  # Max 2 years back\n",
    "            \n",
    "            transaction_date = end_date - timedelta(days=days_back)\n",
    "            \n",
    "            # Add some time of day variation\n",
    "            hour = np.random.choice(range(24), p=[\n",
    "                0.01, 0.01, 0.01, 0.01, 0.01, 0.02,  # 0-5\n",
    "                0.03, 0.04, 0.05, 0.06, 0.07, 0.08,  # 6-11\n",
    "                0.09, 0.08, 0.07, 0.06, 0.05, 0.04,  # 12-17\n",
    "                0.05, 0.06, 0.05, 0.04, 0.03, 0.02   # 18-23\n",
    "            ])\n",
    "            \n",
    "            transaction_date = transaction_date.replace(hour=hour)\n",
    "            \n",
    "            amount = np.random.uniform(*amount_range)\n",
    "            \n",
    "            data.append({\n",
    "                'customer_id': customer,\n",
    "                'transaction_date': transaction_date,\n",
    "                'amount': round(amount, 2),\n",
    "                'customer_type': customer_type  # For validation only\n",
    "            })\n",
    "    \n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "# Create synthetic data\n",
    "df = create_synthetic_data(n_customers=1000)\n",
    "print(f\"Created dataset with {len(df)} transactions for {df['customer_id'].nunique()} customers\")\n",
    "print(f\"Date range: {df['transaction_date'].min()} to {df['transaction_date'].max()}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Basic Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic statistics\n",
    "print(\"Dataset Info:\")\n",
    "print(f\"Total transactions: {len(df):,}\")\n",
    "print(f\"Unique customers: {df['customer_id'].nunique():,}\")\n",
    "print(f\"Date range: {df['transaction_date'].min().date()} to {df['transaction_date'].max().date()}\")\n",
    "print(f\"Total transaction value: ${df['amount'].sum():,.2f}\")\n",
    "print(f\"Average transaction value: ${df['amount'].mean():.2f}\")\n",
    "\n",
    "print(\"\\nTransaction Amount Statistics:\")\n",
    "print(df['amount'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize transaction distribution\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Transaction amount distribution\n",
    "axes[0, 0].hist(df['amount'], bins=50, alpha=0.7, edgecolor='black')\n",
    "axes[0, 0].set_title('Distribution of Transaction Amounts')\n",
    "axes[0, 0].set_xlabel('Amount ($)')\n",
    "axes[0, 0].set_ylabel('Frequency')\n",
    "\n",
    "# Log-transformed amount distribution\n",
    "axes[0, 1].hist(np.log1p(df['amount']), bins=50, alpha=0.7, edgecolor='black')\n",
    "axes[0, 1].set_title('Log-Transformed Transaction Amounts')\n",
    "axes[0, 1].set_xlabel('Log(Amount + 1)')\n",
    "axes[0, 1].set_ylabel('Frequency')\n",
    "\n",
    "# Transactions over time\n",
    "daily_transactions = df.groupby(df['transaction_date'].dt.date).size()\n",
    "axes[1, 0].plot(daily_transactions.index, daily_transactions.values)\n",
    "axes[1, 0].set_title('Daily Transaction Volume')\n",
    "axes[1, 0].set_xlabel('Date')\n",
    "axes[1, 0].set_ylabel('Number of Transactions')\n",
    "axes[1, 0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Transaction hour distribution\n",
    "hourly_dist = df['transaction_date'].dt.hour.value_counts().sort_index()\n",
    "axes[1, 1].bar(hourly_dist.index, hourly_dist.values, alpha=0.7)\n",
    "axes[1, 1].set_title('Transaction Distribution by Hour')\n",
    "axes[1, 1].set_xlabel('Hour of Day')\n",
    "axes[1, 1].set_ylabel('Number of Transactions')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. RFM Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize RFM Analyzer\n",
    "rfm_analyzer = RFMAnalyzer(reference_date=datetime(2024, 12, 31))\n",
    "\n",
    "# Calculate RFM metrics\n",
    "rfm_data = rfm_analyzer.calculate_rfm(\n",
    "    df.drop('customer_type', axis=1),  # Remove the synthetic label\n",
    "    customer_id_col='customer_id',\n",
    "    transaction_date_col='transaction_date',\n",
    "    amount_col='amount'\n",
    ")\n",
    "\n",
    "print(\"RFM Metrics calculated:\")\n",
    "print(rfm_data.head())\n",
    "print(\"\\nRFM Statistics:\")\n",
    "print(rfm_data[['recency', 'frequency', 'monetary_total', 'monetary_avg']].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize RFM distributions\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Recency distribution\n",
    "axes[0, 0].hist(rfm_data['recency'], bins=30, alpha=0.7, edgecolor='black')\n",
    "axes[0, 0].set_title('Recency Distribution (Days since last transaction)')\n",
    "axes[0, 0].set_xlabel('Days')\n",
    "axes[0, 0].set_ylabel('Number of Customers')\n",
    "\n",
    "# Frequency distribution\n",
    "axes[0, 1].hist(rfm_data['frequency'], bins=30, alpha=0.7, edgecolor='black')\n",
    "axes[0, 1].set_title('Frequency Distribution (Number of transactions)')\n",
    "axes[0, 1].set_xlabel('Number of Transactions')\n",
    "axes[0, 1].set_ylabel('Number of Customers')\n",
    "\n",
    "# Monetary distribution\n",
    "axes[1, 0].hist(rfm_data['monetary_total'], bins=30, alpha=0.7, edgecolor='black')\n",
    "axes[1, 0].set_title('Monetary Distribution (Total spent)')\n",
    "axes[1, 0].set_xlabel('Total Amount ($)')\n",
    "axes[1, 0].set_ylabel('Number of Customers')\n",
    "\n",
    "# Average transaction amount\n",
    "axes[1, 1].hist(rfm_data['monetary_avg'], bins=30, alpha=0.7, edgecolor='black')\n",
    "axes[1, 1].set_title('Average Transaction Amount Distribution')\n",
    "axes[1, 1].set_xlabel('Average Amount ($)')\n",
    "axes[1, 1].set_ylabel('Number of Customers')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create RFM scores\n",
    "rfm_scores = rfm_analyzer.create_rfm_scores(rfm_data)\n",
    "\n",
    "print(\"RFM Scores created:\")\n",
    "print(rfm_scores[['customer_id', 'r_score', 'f_score', 'm_score', 'rfm_score']].head())\n",
    "\n",
    "# Visualize score distributions\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "for i, score in enumerate(['r_score', 'f_score', 'm_score']):\n",
    "    score_counts = rfm_scores[score].value_counts().sort_index()\n",
    "    axes[i].bar(score_counts.index, score_counts.values, alpha=0.7)\n",
    "    axes[i].set_title(f'{score.upper()} Distribution')\n",
    "    axes[i].set_xlabel('Score')\n",
    "    axes[i].set_ylabel('Number of Customers')\n",
    "    axes[i].set_xticks(range(1, 6))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Risk Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create risk segments\n",
    "risk_segments = rfm_analyzer.create_risk_segments(rfm_scores)\n",
    "\n",
    "print(\"Risk Segments created:\")\n",
    "print(\"\\nSegment Distribution:\")\n",
    "segment_dist = risk_segments['segment'].value_counts()\n",
    "print(segment_dist)\n",
    "\n",
    "print(\"\\nRisk Category Distribution:\")\n",
    "risk_dist = risk_segments['risk_category'].value_counts()\n",
    "print(risk_dist)\n",
    "\n",
    "print(\"\\nDefault Proxy Distribution:\")\n",
    "default_dist = risk_segments['default_proxy'].value_counts()\n",
    "print(f\"Good customers (0): {default_dist[0]} ({default_dist[0]/len(risk_segments)*100:.1f}%)\")\n",
    "print(f\"Bad customers (1): {default_dist[1]} ({default_dist[1]/len(risk_segments)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize segments\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# Customer segments\n",
    "segment_counts = risk_segments['segment'].value_counts()\n",
    "axes[0].pie(segment_counts.values, labels=segment_counts.index, autopct='%1.1f%%', startangle=90)\n",
    "axes[0].set_title('Customer Segments Distribution')\n",
    "\n",
    "# Risk categories\n",
    "risk_counts = risk_segments['risk_category'].value_counts()\n",
    "colors = ['green', 'orange', 'red']\n",
    "axes[1].pie(risk_counts.values, labels=risk_counts.index, autopct='%1.1f%%', \n",
    "           colors=colors[:len(risk_counts)], startangle=90)\n",
    "axes[1].set_title('Risk Categories Distribution')\n",
    "\n",
    "# Default proxy\n",
    "default_counts = risk_segments['default_proxy'].value_counts()\n",
    "labels = ['Good (0)', 'Bad (1)']\n",
    "colors = ['lightblue', 'lightcoral']\n",
    "axes[2].pie(default_counts.values, labels=labels, autopct='%1.1f%%', \n",
    "           colors=colors, startangle=90)\n",
    "axes[2].set_title('Default Proxy Distribution')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Feature Engineer\n",
    "feature_engineer = FeatureEngineer()\n",
    "\n",
    "# Create transaction features\n",
    "transaction_features = feature_engineer.create_transaction_features(\n",
    "    df.drop('customer_type', axis=1)\n",
    ")\n",
    "\n",
    "print(\"Transaction Features created:\")\n",
    "print(transaction_features.head())\n",
    "print(\"\\nFeature Statistics:\")\n",
    "print(transaction_features.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all features for modeling\n",
    "model_data = feature_engineer.prepare_model_data(risk_segments, transaction_features)\n",
    "\n",
    "print(f\"Model dataset created with {len(model_data)} customers and {len(model_data.columns)} features\")\n",
    "print(\"\\nFeature columns:\")\n",
    "print(model_data.columns.tolist())\n",
    "\n",
    "print(\"\\nTarget variable distribution:\")\n",
    "print(model_data['default_proxy'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Feature Analysis and Correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze feature correlations with target\n",
    "numeric_features = model_data.select_dtypes(include=[np.number]).columns\n",
    "correlations = model_data[numeric_features].corr()['default_proxy'].sort_values(key=abs, ascending=False)\n",
    "\n",
    "print(\"Feature correlations with default_proxy:\")\n",
    "print(correlations.head(15))\n",
    "\n",
    "# Visualize top correlations\n",
    "top_correlations = correlations.head(10)\n",
    "plt.figure(figsize=(10, 6))\n",
    "colors = ['red' if x < 0 else 'blue' for x in top_correlations.values]\n",
    "plt.barh(range(len(top_correlations)), top_correlations.values, color=colors, alpha=0.7)\n",
    "plt.yticks(range(len(top_correlations)), top_correlations.index)\n",
    "plt.xlabel('Correlation with Default Proxy')\n",
    "plt.title('Top 10 Feature Correlations with Default Risk')\n",
    "plt.axvline(x=0, color='black', linestyle='-', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature distributions by risk category\n",
    "key_features = ['recency', 'frequency', 'monetary_total', 'transaction_velocity']\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for i, feature in enumerate(key_features):\n",
    "    for risk_cat in ['Low', 'Medium', 'High']:\n",
    "        data = model_data[model_data['risk_category'] == risk_cat][feature]\n",
    "        if len(data) > 0:\n",
    "            axes[i].hist(data, alpha=0.6, label=f'{risk_cat} Risk', bins=20)\n",
    "    \n",
    "    axes[i].set_title(f'{feature} Distribution by Risk Category')\n",
    "    axes[i].set_xlabel(feature)\n",
    "    axes[i].set_ylabel('Frequency')\n",
    "    axes[i].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Validation Against Synthetic Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate our risk proxy against the synthetic customer types\n",
    "# (This is only possible because we created synthetic data with known labels)\n",
    "\n",
    "# Get customer types for validation\n",
    "customer_types = df.groupby('customer_id')['customer_type'].first().reset_index()\n",
    "validation_data = model_data.merge(customer_types, on='customer_id', how='left')\n",
    "\n",
    "# Cross-tabulation\n",
    "cross_tab = pd.crosstab(validation_data['customer_type'], validation_data['risk_category'])\n",
    "print(\"Cross-tabulation: Synthetic Customer Type vs Risk Category\")\n",
    "print(cross_tab)\n",
    "\n",
    "# Percentage breakdown\n",
    "cross_tab_pct = pd.crosstab(validation_data['customer_type'], validation_data['risk_category'], normalize='index') * 100\n",
    "print(\"\\nPercentage breakdown:\")\n",
    "print(cross_tab_pct.round(1))\n",
    "\n",
    "# Visualize the validation\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(cross_tab_pct, annot=True, fmt='.1f', cmap='RdYlBu_r', cbar_kws={'label': 'Percentage'})\n",
    "plt.title('Customer Type vs Risk Category (% within each customer type)')\n",
    "plt.ylabel('Synthetic Customer Type')\n",
    "plt.xlabel('Predicted Risk Category')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Summary and Insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== EXPLORATORY DATA ANALYSIS SUMMARY ===\")\n",
    "print(f\"\\n1. Dataset Overview:\")\n",
    "print(f\"   - Total transactions: {len(df):,}\")\n",
    "print(f\"   - Unique customers: {df['customer_id'].nunique():,}\")\n",
    "print(f\"   - Average transactions per customer: {len(df) / df['customer_id'].nunique():.1f}\")\n",
    "print(f\"   - Total transaction value: ${df['amount'].sum():,.2f}\")\n",
    "\n",
    "print(f\"\\n2. RFM Analysis Results:\")\n",
    "print(f\"   - Average recency: {rfm_data['recency'].mean():.1f} days\")\n",
    "print(f\"   - Average frequency: {rfm_data['frequency'].mean():.1f} transactions\")\n",
    "print(f\"   - Average monetary value: ${rfm_data['monetary_total'].mean():.2f}\")\n",
    "\n",
    "print(f\"\\n3. Risk Segmentation:\")\n",
    "risk_dist = model_data['risk_category'].value_counts()\n",
    "for category in ['Low', 'Medium', 'High']:\n",
    "    if category in risk_dist.index:\n",
    "        count = risk_dist[category]\n",
    "        pct = count / len(model_data) * 100\n",
    "        print(f\"   - {category} Risk: {count} customers ({pct:.1f}%)\")\n",
    "\n",
    "print(f\"\\n4. Default Proxy:\")\n",
    "default_rate = model_data['default_proxy'].mean() * 100\n",
    "print(f\"   - Default rate: {default_rate:.1f}%\")\n",
    "print(f\"   - Good customers: {(model_data['default_proxy'] == 0).sum()}\")\n",
    "print(f\"   - Bad customers: {(model_data['default_proxy'] == 1).sum()}\")\n",
    "\n",
    "print(f\"\\n5. Key Insights:\")\n",
    "top_corr_features = correlations.head(5).index.tolist()\n",
    "print(f\"   - Top predictive features: {', '.join(top_corr_features)}\")\n",
    "print(f\"   - Model-ready dataset: {len(model_data)} customers, {len(model_data.columns)} features\")\n",
    "print(f\"   - Ready for model training and validation\")\n",
    "\n",
    "print(\"\\n=== NEXT STEPS ===\")\n",
    "print(\"1. Train multiple models (Logistic Regression, Random Forest, XGBoost)\")\n",
    "print(\"2. Evaluate model performance using appropriate metrics\")\n",
    "print(\"3. Implement model interpretability and explainability\")\n",
    "print(\"4. Deploy the best model via API\")\n",
    "print(\"5. Set up monitoring and model drift detection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save processed data for model training\n",
    "model_data.to_csv('../data/processed/model_data.csv', index=False)\n",
    "print(\"Model data saved to '../data/processed/model_data.csv'\")\n",
    "\n",
    "# Save RFM analysis results\n",
    "risk_segments.to_csv('../data/processed/rfm_analysis.csv', index=False)\n",
    "print(\"RFM analysis saved to '../data/processed/rfm_analysis.csv'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
